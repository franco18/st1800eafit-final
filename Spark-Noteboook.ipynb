{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark LDA Implementacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b8922d027594d85bb59e9d6b5bebaed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>2</td><td>application_1561150946879_0003</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-25-247.ec2.internal:20888/proxy/application_1561150946879_0003/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-30-179.ec2.internal:8042/node/containerlogs/container_1561150946879_0003_01_000001/livy\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import monotonically_increasing_id, col, expr, when, concat, lit, isnan\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorIndexer, VectorAssembler, StringIndexer, OneHotEncoder\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, RegressionEvaluator, BinaryClassificationEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer, CountVectorizer\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.linalg import Vectors, SparseVector\n",
    "from pyspark.ml.clustering import LDA, BisectingKMeans\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import wordnet\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import codecs\n",
    "from nltk.corpus import stopwords\n",
    " \n",
    "stop_words_nltk = list(set(stopwords.words('english')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d37d2b18f9ff48c884bb39adcea10ac6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.session.SparkSession object at 0x7efd35672ad0>"
     ]
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leer Informacion desde S3\n",
    "Leemos un news.csv desde s3 para cargarlo en un df de spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8ccebf4551d43a1a901796389f6e8a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df=spark.read.csv(\"s3a://finaltext/news.csv\", inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de9917eb172341f39ea7be34bcffe6b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- id_news: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- publication: string (nullable = true)\n",
      " |-- author: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- year: string (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- url: string (nullable = true)\n",
      " |-- content: string (nullable = true)"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3b62cf1c43b4709b629fb540a4ce9ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df= df.fillna({'content': ''})\n",
    "df= df.fillna({'author': ''})\n",
    "df= df.fillna({'title': ''})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0938818a436d41f48e06658dc73e2dab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = df.select(concat(col(\"title\"), lit(\" \"), col(\"content\"), lit(\" \"), col(\"author\")).alias(\"news\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4624a9e02e1443c2a1f987171f5f4613",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                news|\n",
      "+--------------------+\n",
      "|House Republicans...|\n",
      "|Rift Between Offi...|\n",
      "|Tyrus Wong, ‘Bamb...|\n",
      "|Among Deaths in 2...|\n",
      "|Kim Jong-un Says ...|\n",
      "|Sick With a Cold,...|\n",
      "|Taiwan’s Presiden...|\n",
      "|After ‘The Bigges...|\n",
      "|First, a Mixtape....|\n",
      "|Calling on Angels...|\n",
      "|Weak Federal Powe...|\n",
      "|Can Carbon Captur...|\n",
      "|Mar-a-Lago, the F...|\n",
      "|How to form healt...|\n",
      "|Turning Your Vaca...|\n",
      "+--------------------+\n",
      "only showing top 15 rows"
     ]
    }
   ],
   "source": [
    "df.show(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e248924389a4f3fb03e31975239a189",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = df.withColumn(\"uid\", monotonically_increasing_id())     # Create Unique ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "183575c8cbdc457e91162920b80852b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---+\n",
      "|                news|uid|\n",
      "+--------------------+---+\n",
      "|House Republicans...|  0|\n",
      "|Rift Between Offi...|  1|\n",
      "|Tyrus Wong, ‘Bamb...|  2|\n",
      "|Among Deaths in 2...|  3|\n",
      "|Kim Jong-un Says ...|  4|\n",
      "|Sick With a Cold,...|  5|\n",
      "|Taiwan’s Presiden...|  6|\n",
      "|After ‘The Bigges...|  7|\n",
      "|First, a Mixtape....|  8|\n",
      "|Calling on Angels...|  9|\n",
      "|Weak Federal Powe...| 10|\n",
      "|Can Carbon Captur...| 11|\n",
      "|Mar-a-Lago, the F...| 12|\n",
      "|How to form healt...| 13|\n",
      "|Turning Your Vaca...| 14|\n",
      "|As Second Avenue ...| 15|\n",
      "|Dylann Roof Himse...| 16|\n",
      "|Modi’s Cash Ban B...| 17|\n",
      "|Suicide Bombing i...| 18|\n",
      "|Fecal Pollution T...| 19|\n",
      "+--------------------+---+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "df.show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpiamos las noticias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6b7374ab375478a87cf75befd036340",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def cleanup_text(record):\n",
    "    content = record[0]\n",
    "    words = content.split()\n",
    "    lemmatizer = WordNetLemmatizer() #lemmatizer.lemmatize(word, get_wordnet_pos(word))\n",
    "    stemmer = PorterStemmer()\n",
    "    # Custom List of Stopwords - Add your own here\n",
    "    stopwords_custom = ['']\n",
    "    stopwords = stop_words_nltk + stopwords_custom  \n",
    "    \n",
    "    text_out = [re.sub('[^a-zA-Z0-9]','',word) for word in words]                                       # Remove special characters\n",
    "    text_out = [word.lower() for word in text_out if len(word)>2 and word.lower() not in stopwords]     # Remove stopwords and words under X length\n",
    "    text_out = [lemmatizer.lemmatize(stemmer.stem(word.lower())) for word in text_out]    \n",
    "    return text_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55e0b35456b149d38140a6ac393c92af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "udf_cleantext = udf(cleanup_text , ArrayType(StringType()))\n",
    "clean_text = df.withColumn(\"words\", udf_cleantext(struct([df[x] for x in df.columns])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33d10c74db5d4fc9a00ec3318a6d4ffb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---+--------------------+\n",
      "|                news|uid|               words|\n",
      "+--------------------+---+--------------------+\n",
      "|House Republicans...|  0|[hous, republican...|\n",
      "|Rift Between Offi...|  1|[rift, offic, res...|\n",
      "+--------------------+---+--------------------+\n",
      "only showing top 2 rows"
     ]
    }
   ],
   "source": [
    "clean_text.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1838aa0532df4c338913436a23bd6a1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[news: string, uid: bigint, words: array<string>]"
     ]
    }
   ],
   "source": [
    "clean_text.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00aca475c04e4024a5bfce5c98c92b23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True"
     ]
    }
   ],
   "source": [
    "clean_text.is_cached"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construimos el Bag of Words usando CountVectorizer y IDF de mllib de pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81a0fb73c0e54594a15d60c25f69853f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv = CountVectorizer(inputCol=\"words\", outputCol=\"rawFeatures\", vocabSize = 1000)\n",
    "cvmodel = cv.fit(clean_text)\n",
    "featurizedData = cvmodel.transform(clean_text)\n",
    "\n",
    "vocab = cvmodel.vocabulary\n",
    "vocab_broadcast = sc.broadcast(vocab)\n",
    "\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "idfModel = idf.fit(featurizedData)\n",
    "rescaledData = idfModel.transform(featurizedData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63cbba5bbb4b4db0a9f3d1860ebb6369",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---+--------------------+--------------------+--------------------+\n",
      "|                news|uid|               words|         rawFeatures|            features|\n",
      "+--------------------+---+--------------------+--------------------+--------------------+\n",
      "|House Republicans...|  0|[hous, republican...|(1000,[0,1,2,3,4,...|(1000,[0,1,2,3,4,...|\n",
      "|Rift Between Offi...|  1|[rift, offic, res...|(1000,[0,2,3,4,5,...|(1000,[0,2,3,4,5,...|\n",
      "|Tyrus Wong, ‘Bamb...|  2|[tyru, wong, bamb...|(1000,[0,2,4,5,6,...|(1000,[0,2,4,5,6,...|\n",
      "|Among Deaths in 2...|  3|[among, death, 20...|(1000,[0,2,3,4,5,...|(1000,[0,2,3,4,5,...|\n",
      "|Kim Jong-un Says ...|  4|[kim, jongun, say...|(1000,[0,1,3,5,6,...|(1000,[0,1,3,5,6,...|\n",
      "|Sick With a Cold,...|  5|[sick, cold, quee...|(1000,[0,6,9,10,1...|(1000,[0,6,9,10,1...|\n",
      "|Taiwan’s Presiden...|  6|[taiwan, presid, ...|(1000,[0,1,2,3,4,...|(1000,[0,1,2,3,4,...|\n",
      "|After ‘The Bigges...|  7|[biggest, loser, ...|(1000,[0,2,3,4,5,...|(1000,[0,2,3,4,5,...|\n",
      "|First, a Mixtape....|  8|[first, mixtap, r...|(1000,[0,2,3,4,6,...|(1000,[0,2,3,4,6,...|\n",
      "|Calling on Angels...|  9|[call, angel, end...|(1000,[0,2,4,6,8,...|(1000,[0,2,4,6,8,...|\n",
      "+--------------------+---+--------------------+--------------------+--------------------+\n",
      "only showing top 10 rows"
     ]
    }
   ],
   "source": [
    "rescaledData.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b20dbdac3b1a49b8ae7c836466b650a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[news: string, uid: bigint, words: array<string>, rawFeatures: vector, features: vector]"
     ]
    }
   ],
   "source": [
    "rescaledData.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corremos el mododelo para seleccion de topicos Latent Dirichlet Allocation LDA de pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6415caa1e06047d5be9763284cd3578d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------------------------------------------------------------------+\n",
      "|topic|topic_desc                                                                   |\n",
      "+-----+-----------------------------------------------------------------------------+\n",
      "|0    |[said, compani, polic, year, trump, peopl, one, say, new, state]             |\n",
      "|1    |[trump, said, state, peopl, say, clinton, presid, would, one, like]          |\n",
      "|2    |[trump, said, say, peopl, like, one, woman, year, would, get]                |\n",
      "|3    |[trump, said, russia, state, russian, say, peopl, presid, would, one]        |\n",
      "|4    |[trump, clinton, said, state, say, republican, peopl, presid, vote, democrat]|\n",
      "|5    |[trump, said, state, comey, presid, percent, clinton, isi, fbi, republican]  |\n",
      "|6    |[trump, clinton, said, say, peopl, state, presid, would, republican, like]   |\n",
      "|7    |[trump, clinton, said, say, peopl, like, would, appl, republican, state]     |\n",
      "|8    |[trump, clinton, said, rubio, cruz, republican, presid, campaign, vote, say] |\n",
      "|9    |[said, peopl, korea, trump, say, polic, one, north, like, year]              |\n",
      "+-----+-----------------------------------------------------------------------------+"
     ]
    }
   ],
   "source": [
    "lda = LDA(k=10, seed=123, optimizer=\"em\", featuresCol=\"features\")\n",
    "\n",
    "ldamodel = lda.fit(rescaledData)\n",
    "\n",
    "ldatopics = ldamodel.describeTopics()\n",
    "\n",
    "def map_termID_to_Word(termIndices):\n",
    "    words = []\n",
    "    for termID in termIndices:\n",
    "        words.append(vocab_broadcast.value[termID])\n",
    "    \n",
    "    return words\n",
    "\n",
    "udf_map_termID_to_Word = udf(map_termID_to_Word , ArrayType(StringType()))\n",
    "ldatopics_mapped = ldatopics.withColumn(\"topic_desc\", udf_map_termID_to_Word(ldatopics.termIndices))\n",
    "ldatopics_mapped.select(ldatopics_mapped.topic, ldatopics_mapped.topic_desc).show(50,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d15525b8b3874fd0a4c413d457fdda41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ldaResults = ldamodel.transform(rescaledData)\n",
    "ldaResults = ldaResults.select('uid','news','words','rawFeatures','features','topicDistribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92d0666ac782415d95297677d56707db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|uid|                news|               words|         rawFeatures|            features|   topicDistribution|\n",
      "+---+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|  0|House Republicans...|[hous, republican...|(1000,[0,1,2,3,4,...|(1000,[0,1,2,3,4,...|[0.03091270065332...|\n",
      "|  1|Rift Between Offi...|[rift, offic, res...|(1000,[0,2,3,4,5,...|(1000,[0,2,3,4,5,...|[0.64206719353116...|\n",
      "|  2|Tyrus Wong, ‘Bamb...|[tyru, wong, bamb...|(1000,[0,2,4,5,6,...|(1000,[0,2,4,5,6,...|[0.10274094722929...|\n",
      "|  3|Among Deaths in 2...|[among, death, 20...|(1000,[0,2,3,4,5,...|(1000,[0,2,3,4,5,...|[0.08045837977475...|\n",
      "|  4|Kim Jong-un Says ...|[kim, jongun, say...|(1000,[0,1,3,5,6,...|(1000,[0,1,3,5,6,...|[0.03669554815878...|\n",
      "|  5|Sick With a Cold,...|[sick, cold, quee...|(1000,[0,6,9,10,1...|(1000,[0,6,9,10,1...|[0.12718317387419...|\n",
      "|  6|Taiwan’s Presiden...|[taiwan, presid, ...|(1000,[0,1,2,3,4,...|(1000,[0,1,2,3,4,...|[0.08284904322799...|\n",
      "|  7|After ‘The Bigges...|[biggest, loser, ...|(1000,[0,2,3,4,5,...|(1000,[0,2,3,4,5,...|[0.05848610321125...|\n",
      "|  8|First, a Mixtape....|[first, mixtap, r...|(1000,[0,2,3,4,6,...|(1000,[0,2,3,4,6,...|[0.04223219993356...|\n",
      "|  9|Calling on Angels...|[call, angel, end...|(1000,[0,2,4,6,8,...|(1000,[0,2,4,6,8,...|[0.10658344163700...|\n",
      "| 10|Weak Federal Powe...|[weak, feder, pow...|(1000,[0,1,2,3,5,...|(1000,[0,1,2,3,5,...|[0.08908069078975...|\n",
      "| 11|Can Carbon Captur...|[carbon, captur, ...|(1000,[0,1,2,3,5,...|(1000,[0,1,2,3,5,...|[0.51700248346227...|\n",
      "| 12|Mar-a-Lago, the F...|[maralago, futur,...|(1000,[0,1,2,4,5,...|(1000,[0,1,2,4,5,...|[0.05293890259609...|\n",
      "| 13|How to form healt...|[form, healthi, h...|(1000,[2,3,4,6,7,...|(1000,[2,3,4,6,7,...|[0.07338874184697...|\n",
      "| 14|Turning Your Vaca...|[turn, vacat, pho...|(1000,[0,2,3,4,5,...|(1000,[0,2,3,4,5,...|[0.34634972985304...|\n",
      "| 15|As Second Avenue ...|[second, avenu, s...|(1000,[0,2,4,5,6,...|(1000,[0,2,4,5,6,...|[0.17925133493965...|\n",
      "| 16|Dylann Roof Himse...|[dylann, roof, re...|(1000,[0,2,3,4,5,...|(1000,[0,2,3,4,5,...|[0.16050324538393...|\n",
      "| 17|Modi’s Cash Ban B...|[modi, cash, ban,...|(1000,[0,1,2,3,4,...|(1000,[0,1,2,3,4,...|[0.14283903627444...|\n",
      "| 18|Suicide Bombing i...|[suicid, bomb, ba...|(1000,[0,4,6,7,9,...|(1000,[0,4,6,7,9,...|[0.31443303565711...|\n",
      "| 19|Fecal Pollution T...|[fecal, pollut, t...|(1000,[0,3,4,7,9,...|(1000,[0,3,4,7,9,...|[0.13122537887158...|\n",
      "+---+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "ldaResults.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "239a0de66e524b0491361c8f296be190",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|uid|                news|               words|         rawFeatures|            features|   topicDistribution|topic_prin|\n",
      "+---+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|  0|House Republicans...|[hous, republican...|(1000,[0,1,2,3,4,...|(1000,[0,1,2,3,4,...|[0.03091270065332...|         5|\n",
      "|  1|Rift Between Offi...|[rift, offic, res...|(1000,[0,2,3,4,5,...|(1000,[0,2,3,4,5,...|[0.64206719353116...|         0|\n",
      "|  2|Tyrus Wong, ‘Bamb...|[tyru, wong, bamb...|(1000,[0,2,4,5,6,...|(1000,[0,2,4,5,6,...|[0.10274094722929...|         9|\n",
      "|  3|Among Deaths in 2...|[among, death, 20...|(1000,[0,2,3,4,5,...|(1000,[0,2,3,4,5,...|[0.08045837977475...|         2|\n",
      "|  4|Kim Jong-un Says ...|[kim, jongun, say...|(1000,[0,1,3,5,6,...|(1000,[0,1,3,5,6,...|[0.03669554815878...|         9|\n",
      "|  5|Sick With a Cold,...|[sick, cold, quee...|(1000,[0,6,9,10,1...|(1000,[0,6,9,10,1...|[0.12718317387419...|         0|\n",
      "|  6|Taiwan’s Presiden...|[taiwan, presid, ...|(1000,[0,1,2,3,4,...|(1000,[0,1,2,3,4,...|[0.08284904322799...|         8|\n",
      "|  7|After ‘The Bigges...|[biggest, loser, ...|(1000,[0,2,3,4,5,...|(1000,[0,2,3,4,5,...|[0.05848610321125...|         2|\n",
      "|  8|First, a Mixtape....|[first, mixtap, r...|(1000,[0,2,3,4,6,...|(1000,[0,2,3,4,6,...|[0.04223219993356...|         2|\n",
      "|  9|Calling on Angels...|[call, angel, end...|(1000,[0,2,4,6,8,...|(1000,[0,2,4,6,8,...|[0.10658344163700...|         2|\n",
      "+---+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 10 rows"
     ]
    }
   ],
   "source": [
    "def select_topic_udf(topicDistribution):\n",
    "    dom = topicDistribution[0]\n",
    "    index_dom = 0\n",
    "    for index in range(len(topicDistribution)):\n",
    "        if (topicDistribution[index]>dom):\n",
    "            dom=topicDistribution[index]\n",
    "            index_dom=index\n",
    "    \n",
    "    return index_dom\n",
    "\n",
    "udf_seltop = udf(select_topic_udf , IntegerType())\n",
    "ldaResults = ldaResults.withColumn(\"topic_prin\", udf_seltop(ldaResults.topicDistribution))\n",
    "\n",
    "\n",
    "ldaResults.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
